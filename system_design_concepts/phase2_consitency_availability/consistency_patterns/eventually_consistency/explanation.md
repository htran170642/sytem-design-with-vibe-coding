# Giáº£i thÃ­ch chi tiáº¿t `eventual_cache.py`

ÄÃ¢y lÃ  demo vá» **Eventual Consistency** - há»‡ thá»‘ng distributed cache vá»›i 3 nodes cÃ³ thá»ƒ táº¡m thá»i khÃ´ng nháº¥t quÃ¡n, nhÆ°ng cuá»‘i cÃ¹ng sáº½ há»™i tá»¥.

---

## **Kiáº¿n trÃºc tá»•ng quan**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Node A    â”‚â”€â”€â”€â”€â–¶â”‚   Node B    â”‚â”€â”€â”€â”€â–¶â”‚   Node C    â”‚
â”‚             â”‚â—€â”€â”€â”€â”€â”‚             â”‚â—€â”€â”€â”€â”€â”‚             â”‚
â”‚ data: {}    â”‚     â”‚ data: {}    â”‚     â”‚ data: {}    â”‚
â”‚ versions:{}â”‚     â”‚ versions:{}â”‚     â”‚ versions:{}â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â–²                    â–²                    â–²
     â”‚                    â”‚                    â”‚
   Write                Read                 Read
  (instant)           (may be              (may be
                       stale)               stale)
```

Má»—i node:
- CÃ³ **local data** riÃªng
- Tá»± replicate sang cÃ¡c peers **khÃ´ng Ä‘á»“ng bá»™** (async)
- Giáº£i quyáº¿t conflicts báº±ng **Last-Write-Wins** (LWW)

---

## **1. Khá»Ÿi táº¡o Node**

```python
class EventuallyConsistentCache:
    def __init__(self, node_id, peers=None):
        self.node_id = node_id           # ID cá»§a node nÃ y (vd: "Node-A")
        self.peers = peers or []         # Danh sÃ¡ch cÃ¡c nodes khÃ¡c
        
        self.data = {}                   # Dá»¯ liá»‡u local: {key: {value, timestamp, version}}
        self.versions = defaultdict(     # Version vector cho tá»«ng key
            lambda: defaultdict(int)     # {key: {node_id: version_number}}
        )
        
        self.replication_queue = []      # HÃ ng Ä‘á»£i Ä‘á»ƒ replicate
        
        # Thread ná»n Ä‘á»ƒ replicate async
        self.replication_thread = threading.Thread(
            target=self._replicate_async,
            daemon=True
        )
        self.replication_thread.start()
```

**VÃ­ dá»¥ sau khi khá»Ÿi táº¡o 3 nodes:**
```python
node_a = EventuallyConsistentCache("Node-A")
node_b = EventuallyConsistentCache("Node-B")
node_c = EventuallyConsistentCache("Node-C")

# Káº¿t ná»‘i chÃºng lÃ m peers
node_a.peers = [node_b, node_c]
node_b.peers = [node_a, node_c]
node_c.peers = [node_a, node_b]
```

---

## **2. Ghi dá»¯ liá»‡u (Write) - Local First**

```python
def write(self, key, value):
    # BÆ°á»›c 1: Ghi NGAY vÃ o local (khÃ´ng Ä‘á»£i replicas)
    self.data[key] = {
        'value': value,
        'timestamp': time.time(),
        'version': self.versions[key][self.node_id]
    }
    
    # BÆ°á»›c 2: TÄƒng version cá»§a node nÃ y
    self.versions[key][self.node_id] += 1
    
    print(f"[{self.node_id}] WRITE {key}={value} (local)")
    
    # BÆ°á»›c 3: ThÃªm vÃ o hÃ ng Ä‘á»£i Ä‘á»ƒ replicate SAU (async)
    self.replication_queue.append({
        'key': key,
        'value': value,
        'timestamp': time.time(),
        'version': dict(self.versions[key])  # Snapshot cá»§a version vector
    })
    
    # BÆ°á»›c 4: Tráº£ vá» NGAY Láº¬P Tá»¨C (khÃ´ng Ä‘á»£i replication)
    return "OK"  # â† Low latency!
```

**Timeline cá»§a má»™t write:**

```
T=0ms:   Client gá»i node_a.write('user:123', {'name': 'Alice'})
         
T=0ms:   Node A ghi local âœ“
         data = {'user:123': {'value': {...}, 'timestamp': 1000}}
         versions = {'user:123': {'Node-A': 1, 'Node-B': 0, 'Node-C': 0}}
         
T=0ms:   Tráº£ vá» "OK" cho client âœ“ (FAST!)
         
T=100ms: Background thread replicate tá»›i Node B (async)
T=300ms: Background thread replicate tá»›i Node C (async)
```

**Äiá»ƒm quan trá»ng:**
- âœ… **Write cá»±c nhanh** - chá»‰ ghi local, tráº£ vá» ngay
- âœ… **High availability** - node cÃ³ thá»ƒ write ngay cáº£ khi peers offline
- âŒ **Eventual consistency** - peers chÆ°a cÃ³ dá»¯ liá»‡u ngay láº­p tá»©c

---

## **3. Äá»c dá»¯ liá»‡u (Read) - May Be Stale**

```python
def read(self, key):
    # Äá»c tá»« LOCAL node (cÃ³ thá»ƒ stale)
    if key in self.data:
        value = self.data[key]['value']
        print(f"[{self.node_id}] READ {key}={value} (local)")
        return value
    return None
```

**VÃ­ dá»¥ stale read:**

```python
# T=0ms: Write vÃ o Node A
node_a.write('user:123', {'name': 'Alice', 'age': 30})
# Node A: cÃ³ dá»¯ liá»‡u âœ“
# Node B: CHÆ¯A cÃ³ (replication Ä‘ang trong queue)
# Node C: CHÆ¯A cÃ³

# T=10ms: Äá»c tá»« cÃ¡c nodes khÃ¡c nhau
node_a.read('user:123')  # â†’ {'name': 'Alice', 'age': 30} âœ“
node_b.read('user:123')  # â†’ None (stale! chÆ°a replicate tá»›i)
node_c.read('user:123')  # â†’ None (stale!)

# T=500ms: Sau khi replication hoÃ n táº¥t
node_b.read('user:123')  # â†’ {'name': 'Alice', 'age': 30} âœ“ (now consistent!)
node_c.read('user:123')  # â†’ {'name': 'Alice', 'age': 30} âœ“
```

---

## **4. Replication khÃ´ng Ä‘á»“ng bá»™ (Async)**

```python
def _replicate_async(self):
    """Background thread cháº¡y liÃªn tá»¥c"""
    while True:
        if self.replication_queue:
            # Láº¥y item tá»« queue
            item = self.replication_queue.pop(0)
            
            # Giáº£ láº­p network delay (100-500ms)
            time.sleep(random.uniform(0.1, 0.5))
            
            # Gá»­i tá»›i Táº¤T Cáº¢ peers
            for peer in self.peers:
                try:
                    peer.receive_replication(item)
                except Exception as e:
                    # Peer offline? KhÃ´ng sao - thá»­ láº¡i sau
                    # (Eventually consistent - sáº½ sync khi peer online láº¡i)
                    print(f"Failed to replicate: {e}")
        
        time.sleep(0.1)  # Check queue má»—i 100ms
```

**CÆ¡ cháº¿ hoáº¡t Ä‘á»™ng:**

```
Node A writes 'user:123'
â”‚
â”œâ”€ T=0ms:   Write local âœ“
â”œâ”€ T=0ms:   Add to replication_queue
â”‚           queue = [{'key': 'user:123', 'value': {...}, ...}]
â”‚
â”œâ”€ T=100ms: Background thread picks from queue
â”‚           Sleep 100-500ms (simulate network)
â”‚           
â”œâ”€ T=300ms: Send to Node B
â”‚           peer.receive_replication(item)
â”‚           
â””â”€ T=500ms: Send to Node C
            peer.receive_replication(item)
```

---

## **5. Nháº­n Replication - Giáº£i quyáº¿t Conflicts**

ÄÃ¢y lÃ  pháº§n **QUAN TRá»ŒNG NHáº¤T** - khi nháº­n dá»¯ liá»‡u replicated, cÃ³ thá»ƒ cÃ³ **conflict**!

```python
def receive_replication(self, item):
    key = item['key']
    value = item['value']
    incoming_version = item['version']
    
    # Case 1: Key chÆ°a tá»“n táº¡i - khÃ´ng conflict
    if key not in self.data:
        self.data[key] = {
            'value': value,
            'timestamp': item['timestamp'],
            'version': incoming_version
        }
        print(f"[{self.node_id}] REPLICATED {key}={value}")
    
    # Case 2: Key Ä‘Ã£ tá»“n táº¡i - CONFLICT!
    else:
        # So sÃ¡nh timestamp (Last-Write-Wins)
        if item['timestamp'] > self.data[key]['timestamp']:
            # Incoming data má»›i hÆ¡n â†’ cháº¥p nháº­n
            print(f"[{self.node_id}] CONFLICT {key}: "
                  f"{self.data[key]['value']} -> {value} (LWW)")
            
            self.data[key] = {
                'value': value,
                'timestamp': item['timestamp'],
                'version': incoming_version
            }
    
    # Merge version vectors (quan trá»ng!)
    for node, version in incoming_version.items():
        self.versions[key][node] = max(
            self.versions[key][node],
            version
        )
```

**VÃ­ dá»¥ conflict:**

```python
# Concurrent writes trÃªn 2 nodes khÃ¡c nhau

T=0ms:  Node A writes: user:123 = {age: 30, timestamp: 1000}
T=50ms: Node B writes: user:123 = {age: 31, timestamp: 1050}  # Concurrent!

# Replication happens:
T=500ms: Node A nháº­n replication tá»« Node B
         Local:    {age: 30, timestamp: 1000}
         Incoming: {age: 31, timestamp: 1050}
         
         Compare timestamps: 1050 > 1000
         â†’ Cháº¥p nháº­n incoming (Last-Write-Wins)
         â†’ Node A now has {age: 31}

T=600ms: Node B nháº­n replication tá»« Node A
         Local:    {age: 31, timestamp: 1050}
         Incoming: {age: 30, timestamp: 1000}
         
         Compare timestamps: 1000 < 1050
         â†’ Tá»« chá»‘i incoming (keep local)
         â†’ Node B still has {age: 31}

Result: Both converge to {age: 31} âœ“ (Eventual consistency!)
```

---

## **6. Version Vectors - Theo dÃµi Causality**

Version vectors giÃºp detect conflicts tá»‘t hÆ¡n timestamps.

```python
self.versions = {
    'user:123': {
        'Node-A': 2,  # Node A Ä‘Ã£ update key nÃ y 2 láº§n
        'Node-B': 1,  # Node B Ä‘Ã£ update 1 láº§n
        'Node-C': 0   # Node C chÆ°a update
    }
}
```

**VÃ­ dá»¥ sá»­ dá»¥ng:**

```python
# Initial state
versions['user:123'] = {'A': 0, 'B': 0, 'C': 0}

# Node A updates
node_a.write('user:123', 'value1')
versions['user:123'] = {'A': 1, 'B': 0, 'C': 0}  # A's version++

# Node B updates (concurrent!)
node_b.write('user:123', 'value2')
versions['user:123'] = {'A': 0, 'B': 1, 'C': 0}  # B's version++

# When merging:
# A's version: {'A': 1, 'B': 0, 'C': 0}
# B's version: {'A': 0, 'B': 1, 'C': 0}
# 
# Neither dominates! â†’ Concurrent writes detected
# Use timestamp to break tie (Last-Write-Wins)
```

---

## **7. Demo Flow - Tá»«ng bÆ°á»›c**

```python
def demo_eventual_consistency():
    # Táº¡o 3 nodes
    node_a = EventuallyConsistentCache("Node-A")
    node_b = EventuallyConsistentCache("Node-B")
    node_c = EventuallyConsistentCache("Node-C")
    
    # Káº¿t ná»‘i peers
    node_a.peers = [node_b, node_c]
    node_b.peers = [node_a, node_c]
    node_c.peers = [node_a, node_b]
    
    # === STEP 1: Write to Node A ===
    print("1. Write 'user:123' to Node A")
    node_a.write('user:123', {'name': 'Alice', 'age': 30})
    # Output: [Node-A] WRITE user:123={'name': 'Alice', 'age': 30} (local)
    
    # === STEP 2: Immediate read (stale!) ===
    print("\n2. Immediately read from all nodes:")
    print(f"   Node A: {node_a.read('user:123')}")  # âœ“ Has data
    print(f"   Node B: {node_b.read('user:123')}")  # âœ— None (stale)
    print(f"   Node C: {node_c.read('user:123')}")  # âœ— None (stale)
    
    # === STEP 3: Wait for replication ===
    print("\n3. Wait 1 second for replication...")
    time.sleep(1)
    # Background thread Ä‘Ã£ replicate tá»›i B vÃ  C
    
    # === STEP 4: Read again (consistent now!) ===
    print("\n4. Read after replication:")
    print(f"   Node A: {node_a.read('user:123')}")  # âœ“ Has data
    print(f"   Node B: {node_b.read('user:123')}")  # âœ“ Has data (replicated!)
    print(f"   Node C: {node_c.read('user:123')}")  # âœ“ Has data (replicated!)
    
    # === STEP 5: Concurrent writes (conflict!) ===
    print("\n5. Concurrent writes on different nodes:")
    node_a.write('user:123', {'name': 'Alice', 'age': 31})  # T=1000
    time.sleep(0.05)
    node_b.write('user:123', {'name': 'Alice', 'age': 32})  # T=1050 (later)
    
    # === STEP 6: Wait for conflict resolution ===
    print("\n6. Wait for conflict resolution...")
    time.sleep(1)
    
    # === STEP 7: All converged (Last-Write-Wins) ===
    print("\n7. Final state (after convergence):")
    print(f"   Node A: {node_a.read('user:123')}")  # age: 32
    print(f"   Node B: {node_b.read('user:123')}")  # age: 32
    print(f"   Node C: {node_c.read('user:123')}")  # age: 32
    print("\n   All nodes converged! (Eventual consistency)")
```

---

## **TÃ³m táº¯t Timeline Ä‘áº§y Ä‘á»§**

```
T=0ms:    node_a.write('user:123', {age: 30})
          â”œâ”€ Node A: {age: 30} âœ“
          â”œâ”€ Node B: None (chÆ°a replicate)
          â””â”€ Node C: None (chÆ°a replicate)

T=100ms:  Replication thread hoáº¡t Ä‘á»™ng
          â””â”€ Queued for replication

T=300ms:  Replicated to Node B
          â”œâ”€ Node A: {age: 30} âœ“
          â”œâ”€ Node B: {age: 30} âœ“ (vá»«a nháº­n)
          â””â”€ Node C: None

T=500ms:  Replicated to Node C
          â”œâ”€ Node A: {age: 30} âœ“
          â”œâ”€ Node B: {age: 30} âœ“
          â””â”€ Node C: {age: 30} âœ“ (EVENTUAL CONSISTENCY Ä‘áº¡t Ä‘Æ°á»£c!)

T=1000ms: Concurrent writes
          node_a.write({age: 31})  @ timestamp 1000
          node_b.write({age: 32})  @ timestamp 1050

T=1500ms: After conflict resolution (LWW)
          â”œâ”€ Node A: {age: 32} âœ“ (accepted B's write - newer timestamp)
          â”œâ”€ Node B: {age: 32} âœ“ (kept own write)
          â””â”€ Node C: {age: 32} âœ“ (merged both, took newer)
          
          ALL CONVERGED! (Eventually consistent)
```

---

## **CÃ¡c khÃ¡i niá»‡m chÃ­nh**

| KhÃ¡i niá»‡m | Giáº£i thÃ­ch | Trong code |
|-----------|-----------|-----------|
| **Eventual Consistency** | Cuá»‘i cÃ¹ng táº¥t cáº£ nodes sáº½ cÃ³ cÃ¹ng data | Sau vÃ i trÄƒm ms, táº¥t cáº£ nodes Ä‘á»“ng bá»™ |
| **Async Replication** | Replicate khÃ´ng Ä‘á»£i, cháº¡y background | `_replicate_async()` thread |
| **Stale Reads** | Äá»c cÃ³ thá»ƒ tráº£ vá» data cÅ© | Node B/C tráº£ vá» `None` ngay sau write |
| **Last-Write-Wins** | Conflict resolution: giá»¯ write má»›i nháº¥t | So sÃ¡nh `timestamp` |
| **Version Vectors** | Theo dÃµi causality cá»§a updates | `self.versions[key][node_id]` |
| **High Availability** | Váº«n write Ä‘Æ°á»£c khi peers offline | Write local ngay, khÃ´ng cáº§n peers |
| **Low Latency** | Write tráº£ vá» ngay, khÃ´ng Ä‘á»£i | `return "OK"` immediately |

---

## **So sÃ¡nh vá»›i Strong Consistency**

| Aspect | Eventual Consistency (code nÃ y) | Strong Consistency |
|--------|-------------------------------|-------------------|
| **Write speed** | Instant (local only) | Slow (wait for all replicas) |
| **Read accuracy** | May be stale | Always latest |
| **Availability** | High (works offline) | Lower (needs quorum) |
| **Conflict** | Possible (LWW resolves) | Prevented (locks) |
| **Use case** | Caching, social media | Banking, inventory |

Hiá»ƒu rá»“i chá»©? CÃ³ cÃ¢u há»i gÃ¬ vá» code khÃ´ng? ðŸ˜Š